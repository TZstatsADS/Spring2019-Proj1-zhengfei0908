{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 Are You Happy Today?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/1_BiVCmiQtCBIdBNcaOKjurg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Load all the required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general descriptions for the libraries from official documents:  \n",
    "+ `pandas`: Pandas provides high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "+ `numpy`: NumPy is the fundamental package for scientific computing in Python.\n",
    "+ `matplotlib`: Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.\n",
    "+ `nltk`: NLTK is a leading platform for building Python programs to work with human language data.\n",
    "  \n",
    "There are some other libraries or functions that I will use later and the description will be attached in the corresponding chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Load the data and have a simple sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from subfolder `data` in the project\n",
    "# confirm that this jupyter is in subfolder `doc`\n",
    "hm_data = pd.read_csv('../data/HappyDB/happydb/data/cleaned_hm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's geta general sense of the data!  \n",
    "For convenience, here is a variables' descriotion copied from official github documents.  \n",
    "+ __hmid (int)__: Happy moment ID\n",
    "+ __wid (int)__: Worker ID\n",
    "+ __reflection_period (str)__: Reflection period used in the instructions provided to the worker (3m or 24h)\n",
    "+ __original_hm (str)__: Original happy moment\n",
    "+ __cleaned_hm (str)__: Cleaned happy moment\n",
    "+ __modified (bool)__: If True, original_hm is \"cleaned up\" to generate cleaned_hm (True or False)\n",
    "+ __predicted_category (str)__: Happiness category label predicted by our classifier (7 categories. Please see the reference for details)\n",
    "+ __ground_truth_category (str)__: Ground truth category label. The value is NaN if the ground truth label is missing for the happy moment\n",
    "+ __num_sentence (int)__: Number of sentences in the happy moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>2</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>1936</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>6227</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27678</td>\n",
       "      <td>45</td>\n",
       "      <td>24h</td>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>leisure</td>\n",
       "      <td>leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27679</td>\n",
       "      <td>195</td>\n",
       "      <td>24h</td>\n",
       "      <td>I made a new recipe for peasant bread, and it ...</td>\n",
       "      <td>I made a new recipe for peasant bread, and it ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>achievement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27680</td>\n",
       "      <td>740</td>\n",
       "      <td>24h</td>\n",
       "      <td>I got gift from my elder brother which was rea...</td>\n",
       "      <td>I got gift from my elder brother which was rea...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27681</td>\n",
       "      <td>3</td>\n",
       "      <td>24h</td>\n",
       "      <td>YESTERDAY MY MOMS BIRTHDAY SO I ENJOYED</td>\n",
       "      <td>YESTERDAY MY MOMS BIRTHDAY SO I ENJOYED</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>enjoy_the_moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27682</td>\n",
       "      <td>4833</td>\n",
       "      <td>24h</td>\n",
       "      <td>Watching cupcake wars with my three teen children</td>\n",
       "      <td>Watching cupcake wars with my three teen children</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid   wid reflection_period  \\\n",
       "0  27673  2053               24h   \n",
       "1  27674     2               24h   \n",
       "2  27675  1936               24h   \n",
       "3  27676   206               24h   \n",
       "4  27677  6227               24h   \n",
       "5  27678    45               24h   \n",
       "6  27679   195               24h   \n",
       "7  27680   740               24h   \n",
       "8  27681     3               24h   \n",
       "9  27682  4833               24h   \n",
       "\n",
       "                                         original_hm  \\\n",
       "0  I went on a successful date with someone I fel...   \n",
       "1  I was happy when my son got 90% marks in his e...   \n",
       "2       I went to the gym this morning and did yoga.   \n",
       "3  We had a serious talk with some friends of our...   \n",
       "4  I went with grandchildren to butterfly display...   \n",
       "5                            I meditated last night.   \n",
       "6  I made a new recipe for peasant bread, and it ...   \n",
       "7  I got gift from my elder brother which was rea...   \n",
       "8            YESTERDAY MY MOMS BIRTHDAY SO I ENJOYED   \n",
       "9  Watching cupcake wars with my three teen children   \n",
       "\n",
       "                                          cleaned_hm  modified  num_sentence  \\\n",
       "0  I went on a successful date with someone I fel...      True             1   \n",
       "1  I was happy when my son got 90% marks in his e...      True             1   \n",
       "2       I went to the gym this morning and did yoga.      True             1   \n",
       "3  We had a serious talk with some friends of our...      True             2   \n",
       "4  I went with grandchildren to butterfly display...      True             1   \n",
       "5                            I meditated last night.      True             1   \n",
       "6  I made a new recipe for peasant bread, and it ...      True             1   \n",
       "7  I got gift from my elder brother which was rea...      True             1   \n",
       "8            YESTERDAY MY MOMS BIRTHDAY SO I ENJOYED      True             1   \n",
       "9  Watching cupcake wars with my three teen children      True             1   \n",
       "\n",
       "  ground_truth_category predicted_category  \n",
       "0                   NaN          affection  \n",
       "1                   NaN          affection  \n",
       "2                   NaN           exercise  \n",
       "3               bonding            bonding  \n",
       "4                   NaN          affection  \n",
       "5               leisure            leisure  \n",
       "6                   NaN        achievement  \n",
       "7                   NaN          affection  \n",
       "8                   NaN   enjoy_the_moment  \n",
       "9                   NaN          affection  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, `cleaned_hm` must be my main focus.  \n",
    "There are so many missing values in `ground_truth_category` that makes it difficult to deal with.  \n",
    "Luckily, we have `predicted_category` which has 7 categories. This might provide some useful information!  \n",
    "And also, official database provides some affiliated `.csv` documents(e.g., `senselabel.csv`, `pets-dict.csv`) which might be useful later.  \n",
    "  \n",
    "Whatever, let's first process `cleaned_hm`.  \n",
    "In general, there are several standard steps for text preprocessing. I summarize below:    \n",
    "1. Transform sentences into words, which is also called `tokenization`.  \n",
    "2. Tag the part of speech, which is called `POS Tagging`(Optional).   \n",
    "3. Remove the punctuation and non-alpha words(e.g. numbers, whitespace).  \n",
    "4. Correct the spelling mistakes.  \n",
    "5. Transform all words into lowercase. \n",
    "6. `Lemmatization/Stemming`.  \n",
    "7. Remove too short words and stopwords.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization and POS tagging\n",
    "ori_hm = hm_data['cleaned_hm'].copy()\n",
    "pos_hm = [nltk.pos_tag(nltk.word_tokenize(sent)) for sent in ori_hm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the punctuation and non-alpha words\n",
    "from string import punctuation\n",
    "import re\n",
    "remove_hm = [[tup for tup in sent if re.search(r'\\D+', tup[0]) and tup[0] not in list(punctuation)] \n",
    "             for sent in pos_hm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Correct the spelling mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyenchant` is a powerful tool to deal with spelling mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45095 spelling mistakes.\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "d = enchant.Dict('en_US') # US English\n",
    "check_hm = [[d.check(tup[0]) for tup in sent] for sent in remove_hm]\n",
    "print('There are {0} spelling mistakes.'.format(len([word for sent in check_hm for word in sent if word == False])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what kind of the spelling mistakes they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mistake word is: n't.\n",
      "The sentence is: Mom brought me lunch home and got me coke, which she didn't forgot me home. \n",
      "\n",
      "The mistake word is: ramen.\n",
      "The sentence is: I ate some ramen yesterday. I don't get to eat a lot of anymore despite how cheap it is and easy to make so the fact I got to actually eat some is refreshing. \n",
      "\n",
      "The mistake word is: chipotle.\n",
      "The sentence is: My best friend brought me a cupcake and chipotle \n",
      "\n",
      "The mistake word is: 's.\n",
      "The sentence is: My husband and I went to my mother's house for dinner and a movie. We had rented the movie and wanted to watch it on my mom's very large TV. I teased mom and my husband for talking during the movie, but it was a great time.  \n",
      "\n",
      "The mistake word is: n't.\n",
      "The sentence is: I saw that I had a shopping credit on Amazon I had forgotten about so I was able to treat myself to a fancy skincare lotion I didn't think I could afford before. \n",
      "\n",
      "The mistake word is: 'd.\n",
      "The sentence is: I received a necklace in the mail I'd ordered that jingles when I move which should soothe the baby in my belly. \n",
      "\n",
      "The mistake word is: soulmate.\n",
      "The sentence is: I found out my friend is getting married to his soulmate. \n",
      "\n",
      "The mistake word is: 's.\n",
      "The sentence is: One event that made me happy was when I was able to express my thoughts coherently during a meeting with my student's parents. \n",
      "\n",
      "The mistake word is: 's.\n",
      "The sentence is: I took care of my sister's new puppy and played with him. \n",
      "\n",
      "The mistake word is: grandma.I.\n",
      "The sentence is: The last small thing that made me surprisingly happy was spending time with my grandma.I went through a phase in my life where I wanted complete autonomy from my family. I felt crushed by the pressures of trying to pursue a career my family wanted from me rather than one I wanted for myself. So, I just wanted to break free from all of them and be as far away as I possibly could, even my grandma whom has been there for me every day for the first 12 years of my life.It wasnat until lately, that I realized the importance of family and how short life can be. My grandma is 96 years old, which means she has a limited time left on this beautiful planet. It made me really sad that I havent made much effort to really spend time with her ever since she moved to her own home. Instead of spending my weekends with her, I chose to go out with friends, date around, sit at home on the computer browsing new music, and basically just waste my time.This weekend, I decided to change that. I called her and spent the entire day with her. Sunday morning, I came to her house, cooked us some pancakes (her favorite), we went to Temple, just like we did when I was a kid, and then we spent the rest of the day at the mall, browsing the stores. I didnt expect it to make me as happy as I had planned, but it really made my day. Iam really glad I did that and I certainly plan to spend a lot more time with her now. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all the indexes for the spelling mistake(False)\n",
    "indexes = [[i,j] for i in range(len(check_hm)) for j,x in enumerate(check_hm[i]) if x == False]\n",
    "\n",
    "# randomly choose 10 some spelling mistakes\n",
    "import random\n",
    "random.seed(1)\n",
    "for i in range(10):\n",
    "    choice = random.choice(range(len(indexes)))\n",
    "    idx1 = indexes[choice][0]\n",
    "    idx2 = indexes[choice][1]\n",
    "    print('The mistake word is: {0}.\\nThe sentence is: {1} \\n'.format(remove_hm[idx1][idx2][0], ori_hm[idx1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the random examples above, some mistakes come from abbreviation(e.g. `don't` will be tokenized into `do` and `n't`) which is very meaningful and can be dealt with by `POS tagging` in `nltk`. Some other mistakes come from special words(e.g `chipotle`, `ramen`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's tough to deal with such spelling problems. But luckily, the mistake rate is only 2.44% which won't lead to a disaster in results.\n"
     ]
    }
   ],
   "source": [
    "print('''It's tough to deal with such spelling problems. But luckily, the mistake rate is only {0:.2f}% which won't lead to a disaster in results.'''.\n",
    "      format(100 * len([word for sent in check_hm for word in sent if word == False])/len([word for sent in check_hm for word in sent])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Transform to lowercase, remove too short words and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to lowercase\n",
    "lower_hm = [[(tup[0].lower(), tup[1]) for tup in sent] for sent in remove_hm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def the function that convert the POS from original form to consistent form\n",
    "from nltk.corpus import wordnet\n",
    "def get_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemma_hm = [[(wnl.lemmatize(tup[0], get_pos(tup[1])), tup[1]) for tup in sent]for sent in lower_hm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Remove too short words and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words whose length < 3 and remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "words = stopwords.words('english') +['happy','ago','yesterday','lot','today','month','day',\n",
    "                                     'last','week','past','get','make','one','take']\n",
    "stop_hm = [[tup for tup in sent \n",
    "            if len(tup[0]) >= 3 and tup[0] not in words and not re.search(r\"^\\'[a-zA-Z]\", tup[0])] \n",
    "           for sent in lemma_hm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - Combine the processed text to the original data and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_data['processed_hm'] = [','.join([tup[0] for tup in sent]) for sent in stop_hm]\n",
    "hm_data.to_csv('../output/processed_hm.csv', index=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>processed_hm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "      <td>successful,date,someone,felt,sympathy,connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>2</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "      <td>son,mark,examination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>1936</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exercise</td>\n",
       "      <td>gym,morning,yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "      <td>serious,talk,friend,flaky,lately,understand,go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>6227</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "      <td>grandchild,butterfly,display,crohn,conservatory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid   wid reflection_period  \\\n",
       "0  27673  2053               24h   \n",
       "1  27674     2               24h   \n",
       "2  27675  1936               24h   \n",
       "3  27676   206               24h   \n",
       "4  27677  6227               24h   \n",
       "\n",
       "                                         original_hm  \\\n",
       "0  I went on a successful date with someone I fel...   \n",
       "1  I was happy when my son got 90% marks in his e...   \n",
       "2       I went to the gym this morning and did yoga.   \n",
       "3  We had a serious talk with some friends of our...   \n",
       "4  I went with grandchildren to butterfly display...   \n",
       "\n",
       "                                          cleaned_hm  modified  num_sentence  \\\n",
       "0  I went on a successful date with someone I fel...      True             1   \n",
       "1  I was happy when my son got 90% marks in his e...      True             1   \n",
       "2       I went to the gym this morning and did yoga.      True             1   \n",
       "3  We had a serious talk with some friends of our...      True             2   \n",
       "4  I went with grandchildren to butterfly display...      True             1   \n",
       "\n",
       "  ground_truth_category predicted_category  \\\n",
       "0                   NaN          affection   \n",
       "1                   NaN          affection   \n",
       "2                   NaN           exercise   \n",
       "3               bonding            bonding   \n",
       "4                   NaN          affection   \n",
       "\n",
       "                                        processed_hm  \n",
       "0   successful,date,someone,felt,sympathy,connection  \n",
       "1                               son,mark,examination  \n",
       "2                                   gym,morning,yoga  \n",
       "3  serious,talk,friend,flaky,lately,understand,go...  \n",
       "4    grandchild,butterfly,display,crohn,conservatory  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
